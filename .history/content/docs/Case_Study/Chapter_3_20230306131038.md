---
title: "Chapter 3 - Geospatial Operation and Analysis" 
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
---


## Introduction 

Why are we interested in geospatial data? Geospatial data is a type of data that is associated with a location. This location can be a point, a line, a polygon, or a raster. Geospatial data is becoming more and more important, yet the sheer volume of information that is generated made it difficult to handle. In this chapter, we will be exploring the use of GPU for manipulating large-scale geospatial data, and provide a practical example of how we can predict the presence of Aedes aegypti across the globe. 
## Objectives 

The objective of the third *Case Study* is to demonstrate the practical application of the common spatial data structures and operation with GPU-accelerated Python packages. The goal here is in twofold: 1) compare the computational speed of calculating point in polygon and 2) compare the computational speed of a classification model with raster data. 

## Predicting the Presence of Aedes aegypti 
In this case study, we will be predicting the global presence and probability of Aedes aegypti, a mosquito species that is known to transmit dengue fever, chikungunya, and Zika virus. You can download the Aedes aegypti point occurrence data across the World from 1958 to 2014 [here](https://github.com/jasoncpit/GPU-Analytics/blob/master/data/Chapter3/aedes_point.csv). We will also be using precipitation, temperature, elevation, and population density as predictor variables to capture the climatic, environmental and demographics variables. You can download the raster data from the GitHub repository [here](https://github.com/jasoncpit/GPU-Analytics/tree/master/data/Chapter3).

### Loading datasets 
To begin, let's load the necessary libraries and datasets. It is important to note that all shape file and raster data (5km resolution) were projected to the CRS: WGS84 4236.
```python
#Import libraries
import rasterio
import geopandas as gpd 
import numpy as np 
import pandas as pd 
import seaborn as sns 
import matplotlib.pyplot as plt 
import cuspatial
import cudf

# Load raster data 
precipitation = rasterio.open('./data/Global Raster/Precipitation/Global Averaged Precipitation 2000-14.tif')
temp = rasterio.open('./data/Global Raster/Temperature/Global Averaged Temperature 2000-14.tif')
elevation = rasterio.open('./data/Global Raster/Elevation/Global Land Surface Elevation.tif')
pop_density = rasterio.open('./data/Global Raster/Population Density/Global Population Density AveragedEst.tif')

# Load Shapefile 
#Loading global shapefile 
global_outline =gpd.read_file('./data/Global Shapefile/Global Outline/Global_All_0.shp',crs='EPSG:4326')
#Loading country shapefiles 
country_outline = gpd.read_file('./data/Global Shapefile/Global with Country Outline/Global_Countries_1.shp',crs='EPSG:4326') 

# Load Point occurrence data 
aedes =pd.read_csv('./data/Global Raster/aedes_point.csv')
aedes_point = gpd.GeoDataFrame(aedes,geometry=gpd.points_from_xy(aedes['longitude'],aedes['latitude']),crs='EPSG:4326')

# Transformation 
global_outline.crs = ('+init=EPSG:4326')
country_outline.crs =('+init=EPSG:4326')  
aedes_point.crs = ('+init=EPSG:4326')

# Check CRS 
print(global_outline.crs ==aedes_point.crs)
```

### Data Visualization 

Let's visualize the point occurrence data and the predictor variables. We will be using the `matplotlib` and `rasterio` packages to visualize the data. 
```python
# Visualise point patterns 
import matplotlib.pyplot as plt 
fig, ax = plt.subplots(1,1, figsize = (10,10)) 
country_outline.plot(edgecolor='black',linewidth=0.1,ax=ax,color="white")
aedes_point.plot(ax=ax,color='red',markersize = 1) 
#show(light,ax=ax,cmap='viridis')
ax.axis('off')
ax.set_title("Distribution of aedes occurence across the World")
```

<figure title = "Global Distribution">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/chp3_global.png?raw=true">
    <figcaption>
    <b>Figure 1: Global Distribution of Aedes aegypti 
    </b>
    </figcaption>
    </center>
</figure>

```python
from rasterio.plot import show 
fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(20,20))
title =["precipitation","temp","elevation","pop_density"] 
for index,attribute in enumerate([precipitation,temp,elevation,pop_density]): 
     image = show(attribute,ax=ax[index//2,index%2],cmap='nipy_spectral',title = title[index])
     image.axis('off')
fig.subplots_adjust(hspace=-0.5, wspace=0)
```

<figure title = "Predictors Distribution">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/chp3_predictors.png?raw=true">
    <figcaption>
    <b>Figure 2: Distribution of Predictors: Precipitation, Temperature, Elevation, and Population Density 
    </b>
    </figcaption>
    </center>
</figure>


### Preparing data for pseudo-background points as absence 

Next, we need to prepare the background data. What is the background data? With Background data we are not attempting to guess point locations where an event is absent. Here, we are rather trying to characterise the environment of the study region. In this sense, background is the same, irrespective of where the point fire are found or not. Background data establishes the environmental domain of the study, whilst presence data should establish under which conditions a fire is more likely to be present than on average. 

There are several ways to generate background data. In R, we can use the `spsample()` function from the `sp` package to generate randomly-distributed points with defined spatial boundaries. However, in Python, there is no pre-built function to help us. Instead, we will generate random points across the world and filter out the points that are outside of the country boundary. Here is the code to generate random points across the world.

```python
# random seed 
import random
from shapely.geometry import Point
from tqdm import tqdm
random.seed(10)
def Random_Points_in_Polygon(polygon, number):
    bound = polygon.bounds.values[0]
    minx, miny, maxx, maxy = bound[0],bound[1],bound[2],bound[3]
    x_point,y_point = np.random.uniform(minx, maxx,size=number),np.random.uniform(miny,maxy,size=number) 
    return x_point,y_point
background_points = Random_Points_in_Polygon(global_outline,aedes_point.shape[0]*5)
background_points_shp = gpd.GeoDataFrame(geometry=gpd.points_from_xy(x=background_points[0],y=background_points[1]),crs='EPSG:4326')
background_points_shp.crs = global_outline.crs 
print("Number of background points: ",background_points_shp.shape[0]) 
#Number of background points:  171108 
```

Figure 3 shows the distribution of background points across the world. We generated 171,108 points that are evenly distributed across the world, with some points located in the ocean. 

```python
# Visualise point patterns 
fig, ax = plt.subplots(1,1, figsize = (10,10)) 
global_outline.plot(edgecolor='black',linewidth=2,ax=ax,color="white")
background_points_shp.plot(ax=ax,color='blue',markersize = 0.1) 
ax.axis('off')
ax.set_title("Distribution of background points across the World")
```


<figure title = "Predictors Distribution">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/chp3_background_point.png?raw=true">
    <figcaption>
    <b>Figure 3: Generating pseudo-background points as absence 
    </b>
    </figcaption>
    </center>
</figure>


### Calculating the point in polygon 

Now that we've created the background points, we need to quickly determine which points occur in each country. This task is commonly known as a Point in Polygon (PIP) query, however, they are usually extremely slow. In Python, we can use the Shapely library's functions `.within()` and `.contains()` to determine if a point is within a polygon or if a polygon contains a point. Nevertheless, these functions are not designed to handle large datasets. Assuming that we have 1 million points and 100 polygons, the `.within()` function will take 100 million comparisons to determine which points are within which polygons. This is a very slow process. 

To speed up the process, we can use the `.sjoin()` function from the GeoPandas library and the `.point_in_polygon` function from the cuSpatial library. The `.point_in_polygon()` function is a GPU-accelerated function that is designed to perform a PIP query on a large number of points and polygons. For the `.point_in_polygon()` function, instead of creating massive points in polygon arrays, we are going to use 31 polygons limit 





<figure title = "Predictors Distribution">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/chp3_filtered_background.png?raw=true">
    <figcaption>
    <b>Figure 4: Filtering the pseudo-background points that are within the country boundary
    </b>
    </figcaption>
    </center>
</figure>


There are other ways to optimize PIP operations, for example, by creating a spatial index or hash tables to [here](https://github.com/Quansight/scipy2020_spatial_algorithms_at_scale/blob/master/spatial_algorithms_at_scale_presentation.pdf)

### Extraction of all raster values from predictor variables onto presence-absence points 


### Preparation of training & test data for prediction & model cross-validation


### Random Forest Classification Model with CuML and Scikit-learn

### Examination of the predictorâ€™s contribution and Model Validation
<figure title = "Predictors Distribution">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/chp3_Feature_importance.png?raw=true">
    <figcaption>
    <b>Figure 5: Feature importance of the Random Forest Classification Model
    </b>
    </figcaption>
    </center>
</figure>

<figure title = "Predictors Distribution">
     <center>
     <p><img src="https://github.com/jasoncpit/GPU-Analytics/blob/master/Pictures/chp3_ROC_curve.png?raw=true">
    <figcaption>
    <b>Figure 6: ROC Curve of the Random Forest Classification Model
    </b>
    </figcaption>
    </center>
</figure>



### Mapping the predicted probability of presence of Aedes aegypti 

### Forecasting the presence of Aedes aegypti in 2050 

### Conclusion 
