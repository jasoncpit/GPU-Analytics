{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf,cuml,cupy \n",
    "import pandas as pd\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as GPU_TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as CPU_TfidfVectorizer\n",
    "import time \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "data1_url = \"https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_account_info.csv\"\n",
    "data2_url = \"https://raw.githubusercontent.com/chris1610/pbpython/master/data/hospital_reimbursement.csv\"\n",
    "\n",
    "account = pd.read_csv(data1_url) #Hospital account information\n",
    "reimbursement = pd.read_csv(data2_url) #Hospital reimbursement information\n",
    "\n",
    "#Converting facility name, address, city and state into one string \n",
    "account_full_address = account.apply(lambda x: \" \".join([x['Facility Name'],x['Address'],x['City'],x['State']]), axis=1).to_list() \n",
    "\n",
    "reimbursement_full_address = reimbursement.apply(lambda x: \" \".join([x['Provider Name'],x['Provider Street Address'],x['Provider City'],x['Provider State']]), axis=1).to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reimbursement.head(2).to_markdown())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization - experimenting the effect of data size on computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititate sklearn vectoriser and cuml vectosier \n",
    "\n",
    "#CPU vectorizer from sklearn \n",
    "cpu_vectorizer = CPU_TfidfVectorizer(analyzer='char',ngram_range=(1,2))\n",
    "#GPU vectorizer from cuml \n",
    "gpu_vectorizer = GPU_TfidfVectorizer(analyzer='char',ngram_range=(1,2))\n",
    "\n",
    "#Here analyzer='char' means we are using character as the input \n",
    "#ngram_range = (1,2) means we are looking at both unigram and bigram for the model input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually inflating number of rows with 10 run times \n",
    "total_datasize = []\n",
    "cpu_time = []\n",
    "gpu_time = [] \n",
    "for run in range(1,10):\n",
    "  for i in range(1,10):\n",
    "    #Manually inflating the number of records \n",
    "    input = reimbursement_full_address*i\n",
    "    total_datasize.append(len(input))\n",
    "    #Cpu runtime \n",
    "    start = time.time()\n",
    "    cpu_output = cpu_vectorizer.fit_transform(input)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    cpu_time.append(elapsed)\n",
    "\n",
    "    #gpu runtime \n",
    "    start = time.time()\n",
    "    #Convert input to cudf series \n",
    "    gpu_output = gpu_vectorizer.fit_transform(cudf.Series(input))\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    gpu_time.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "gpu_elapsed = pd.DataFrame({\"time\":gpu_time,\"data_size\":total_datasize,'label':\"gpu\"})\n",
    "cpu_elapsed = pd.DataFrame({\"time\":cpu_time,\"data_size\":total_datasize,'label':\"cpu\"})\n",
    "result = pd.concat([gpu_elapsed,cpu_elapsed]).reset_index()\n",
    "sns.lineplot(x= 'data_size',y='time',hue = 'label',data = result,ax = ax )\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel(\"Time Elapsed \")\n",
    "plt.title(\"Comparing the speed of TF-IDF vectorisation on CPU and GPU\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consine similarity - experimenting the effect of matrix multiplication on computational time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_target =cpu_vectorizer.transform(account_full_address)\n",
    "gpu_target = gpu_vectorizer.transform(cudf.Series(account_full_address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np \n",
    "import scipy\n",
    "import gc\n",
    "import torch \n",
    "from cupyx.scipy.sparse.linalg import norm as cp_norm\n",
    "from scipy.sparse.linalg import norm as sc_norm \n",
    "\n",
    "def np_cosine_similarity(query, target):\n",
    "    # Assert that the input matrices have the same number of columns\n",
    "    assert(query.shape[1] == target.shape[1])\n",
    "\n",
    "    #Calculate the dot product \n",
    "    dot_product = np.dot(query,target.T)\n",
    "\n",
    "    #Calculate l2 norm for query and target \n",
    "    query_norm = sc_norm(query,axis=1)\n",
    "    target_norm = sc_norm(target,axis=1)\n",
    "\n",
    "    return dot_product/(query_norm[:,np.newaxis]*target_norm[:,np.newaxis].T)\n",
    "\n",
    "#Cupy is a drop-in replacement for numpy \n",
    "def cp_cosine_similarity(query, target):\n",
    "    # Assert that the input matrices have the same number of columns\n",
    "    assert(query.shape[1] == target.shape[1])\n",
    "    #Initiate GPU instance \n",
    "    with cp.cuda.Device(0):\n",
    "        #Create memory pool\n",
    "        pool = cp.get_default_memory_pool()\n",
    "        pool.set_limit(1e9)  # Set the limit of the memory pool to 1 GB\n",
    "        \n",
    "        #Check whether the sparse matrix is compatible with Cupy, if not then convert\n",
    "        if isinstance(query,scipy.sparse._csr.csr_matrix) and isinstance(target,scipy.sparse._csr.csr_matrix):\n",
    "        # Convert the input matrices to sparse format and copy to the GPU\n",
    "            query = cp.sparse.csr_matrix(query, copy=True) \n",
    "            target = cp.sparse.csr_matrix(target, copy=True)\n",
    "        \n",
    "        # Dot product using cupy.dot()\n",
    "        dot_product = query.dot(target.T)\n",
    "        \n",
    "        # Calculate l2 norm for query and target\n",
    "        query_norm = cp_norm(query,axis=1)\n",
    "        target_norm = cp_norm(target,axis=1)\n",
    "        \n",
    "        # Compute the cosine similarity\n",
    "        output = dot_product / (cp.expand_dims(query_norm,axis=1) * cp.expand_dims(target_norm,axis=0))\n",
    "        \n",
    "        #Converting back to numpy array\n",
    "        result = output.get()\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "#Is a JIT compiler for python\n",
    "#You can take function with numerical values or arrays\n",
    "#And compile them to assembley, so they run at high speed \n",
    "#Deploy to compiled on GPU and CUDA \n",
    "\n",
    "#Define the kernel for calculation \n",
    "#- A GPU function launched by the host and executed on the device\n",
    "#Cannot explicity return a numerical value \n",
    "@cuda.jit\n",
    "def pairwise_cosine_similarity(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        dot = 0.0\n",
    "        normA = 0.0\n",
    "        normB = 0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            a = A[i, k]\n",
    "            b = B[j, k]\n",
    "            dot += a * b\n",
    "            normA += a ** 2\n",
    "            normB += b ** 2\n",
    "        C[i, j] = dot / (normA * normB)**0.5\n",
    "\n",
    "def Numba_cuda_cosine_similarity(query,target): \n",
    "     # Assert that the input matrices have the same number of columns\n",
    "    assert(query.shape[1] == target.shape[1])\n",
    "    ## Allocate memory on the device for the result\n",
    "    output = cuda.device_array((query.shape[0],target.shape[0]))\n",
    "\n",
    "\n",
    "    # Convert the input matrices to sparse format and copy to the GPU\n",
    "    query = cuda.to_device(query.toarray())\n",
    "    target = cuda.to_device(target.toarray()) \n",
    "    #Set the number of threads in a block ----- \n",
    "    threadsperblock = (32,32)\n",
    "\n",
    "    # Calculate the number of thread blocks in the grid \n",
    "    blockspergrid_x = (output.shape[0] + (threadsperblock[0] - 1)) // threadsperblock[0]\n",
    "    blockspergrid_y = (output.shape[1] + (threadsperblock[1] - 1)) // threadsperblock[1]\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "    #Starting the kernel \n",
    "    pairwise_cosine_similarity[blockspergrid, threadsperblock](query, target, output)\n",
    "\n",
    "    # Copy the result back to the host\n",
    "    return output.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "total_datasize = []\n",
    "cpu_time = []\n",
    "gpu_time = [] \n",
    "numba_time = [] \n",
    "\n",
    "for size in tqdm(range(1000,cpu_output.shape[0],5000)):\n",
    "    total_datasize.append(size)\n",
    "    query = cpu_output[0:size,]\n",
    "    #CPU --------------\n",
    "    start = time.time()\n",
    "    _ = np_cosine_similarity(query,cpu_target)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    cpu_time.append(elapsed)\n",
    "    \n",
    "    #GPU --------------\n",
    "    start = time.time()\n",
    "    _ = cp_cosine_similarity(query,cpu_target)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    gpu_time.append(elapsed)\n",
    "\n",
    "    #Numba CUDA ---- \n",
    "    start = time.time()\n",
    "    _ = Numba_cuda_cosine_similarity(query,cpu_target)\n",
    "    done = time.time()\n",
    "    elapsed = done - start \n",
    "    numba_time.append(elapsed) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "gpu_elapsed = pd.DataFrame({\"time\":gpu_time,\"data_size\":total_datasize,'label':\"gpu\"})\n",
    "cpu_elapsed = pd.DataFrame({\"time\":cpu_time,\"data_size\":total_datasize,'label':\"cpu\"})\n",
    "numba_elasped = pd.DataFrame({\"time\":numba_time,\"data_size\":total_datasize,'label':\"numba\"}) \n",
    "result = pd.concat([gpu_elapsed,cpu_elapsed,numba_elasped]).reset_index()\n",
    "sns.lineplot(x= 'data_size',y='time',hue = 'label',data = result,ax = ax )\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel(\"Time Elapsed \")\n",
    "plt.title(\"Comparing the speed of matrix multiplication on CPU and GPU\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "#Full - pipeline on GPU \n",
    "reimbursement_tfidf= gpu_vectorizer.fit_transform(cudf.Series(reimbursement_full_address))\n",
    "account_tfidf = gpu_vectorizer.transform(cudf.Series(account_full_address))\n",
    "similarity_matrix = Numba_cuda_cosine_similarity(reimbursement_tfidf,account_tfidf) \n",
    "\n",
    "result = defaultdict(list)\n",
    "#Getting the reimbursement address and state, account address and state \n",
    "for index in range(similarity_matrix.shape[0]):\n",
    "    most_similar_index = similarity_matrix[index].argmax()\n",
    "    result['reimbursement_address'].append(reimbursement_full_address[index]) \n",
    "    result['account_address'].append(account_full_address[most_similar_index])  \n",
    "    result['reimbursment_zip'].append(reimbursement.loc[index,'Provider Zip Code'])\n",
    "    result['account_zip'].append(account.loc[most_similar_index,'ZIP Code']) \n",
    "    result['similarity_score'].append(similarity_matrix[index][most_similar_index])\n",
    "\n",
    "result_df = pd.DataFrame(result).sort_values('similarity_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(result_df.reimbursment_zip,result_df.account_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "result_df.similarity_score.plot(kind='hist',bins=10,ax=ax)\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.title('Distribution of cosine similarity score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.sort_values('similarity_score',ascending=True).head(2).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.sort_values('similarity_score',ascending=False).head(2).to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
